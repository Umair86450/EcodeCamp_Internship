{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oeiNPXHpH-cn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10  # Example with CIFAR-10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJwntbvhIFFQ",
    "outputId": "5bbb2e34-902f-4825-fa8e-3610803e76ae"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001B[1m170498071/170498071\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 0us/step\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n"
   ],
   "metadata": {
    "id": "d87glstvILD_"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ],
   "metadata": {
    "id": "NClaw_rTIMtU"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)"
   ],
   "metadata": {
    "id": "3n_3ouH7IOXb"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ],
   "metadata": {
    "id": "GAUsV_q6IPHG"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bM3fdvefISXA",
    "outputId": "e4ed4a8c-f4e7-4819-bb7d-48b1f2b891b4"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "id": "Ul2DMEr2IUcT"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=64), validation_data=(X_test, y_test), epochs=20)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r41EIFFIIWCs",
    "outputId": "11a2c9ab-86e7-45ed-d874-a173446c7839"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 46ms/step - accuracy: 0.6497 - loss: 1.0169 - val_accuracy: 0.6983 - val_loss: 0.8773\n",
      "Epoch 2/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 45ms/step - accuracy: 0.6484 - loss: 1.0126 - val_accuracy: 0.7043 - val_loss: 0.8522\n",
      "Epoch 3/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 46ms/step - accuracy: 0.6540 - loss: 1.0017 - val_accuracy: 0.7099 - val_loss: 0.8455\n",
      "Epoch 4/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 45ms/step - accuracy: 0.6465 - loss: 1.0104 - val_accuracy: 0.7107 - val_loss: 0.8389\n",
      "Epoch 5/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 44ms/step - accuracy: 0.6604 - loss: 0.9878 - val_accuracy: 0.6894 - val_loss: 0.8917\n",
      "Epoch 6/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 46ms/step - accuracy: 0.6594 - loss: 0.9819 - val_accuracy: 0.7150 - val_loss: 0.8410\n",
      "Epoch 7/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 44ms/step - accuracy: 0.6617 - loss: 0.9690 - val_accuracy: 0.7143 - val_loss: 0.8415\n",
      "Epoch 8/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 43ms/step - accuracy: 0.6615 - loss: 0.9670 - val_accuracy: 0.7037 - val_loss: 0.8506\n",
      "Epoch 9/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 43ms/step - accuracy: 0.6581 - loss: 0.9806 - val_accuracy: 0.7213 - val_loss: 0.8064\n",
      "Epoch 10/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 44ms/step - accuracy: 0.6684 - loss: 0.9535 - val_accuracy: 0.7271 - val_loss: 0.7972\n",
      "Epoch 11/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 44ms/step - accuracy: 0.6702 - loss: 0.9582 - val_accuracy: 0.7202 - val_loss: 0.8107\n",
      "Epoch 12/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 44ms/step - accuracy: 0.6668 - loss: 0.9574 - val_accuracy: 0.7024 - val_loss: 0.8538\n",
      "Epoch 13/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 44ms/step - accuracy: 0.6722 - loss: 0.9365 - val_accuracy: 0.7141 - val_loss: 0.8267\n",
      "Epoch 14/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 44ms/step - accuracy: 0.6671 - loss: 0.9478 - val_accuracy: 0.7343 - val_loss: 0.7722\n",
      "Epoch 15/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 44ms/step - accuracy: 0.6686 - loss: 0.9378 - val_accuracy: 0.7188 - val_loss: 0.8343\n",
      "Epoch 16/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 43ms/step - accuracy: 0.6749 - loss: 0.9383 - val_accuracy: 0.7102 - val_loss: 0.8439\n",
      "Epoch 17/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 44ms/step - accuracy: 0.6790 - loss: 0.9299 - val_accuracy: 0.7369 - val_loss: 0.7670\n",
      "Epoch 18/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 44ms/step - accuracy: 0.6770 - loss: 0.9256 - val_accuracy: 0.7062 - val_loss: 0.8499\n",
      "Epoch 19/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 45ms/step - accuracy: 0.6809 - loss: 0.9180 - val_accuracy: 0.7299 - val_loss: 0.7718\n",
      "Epoch 20/20\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 43ms/step - accuracy: 0.6779 - loss: 0.9227 - val_accuracy: 0.7275 - val_loss: 0.7896\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Save the model\n",
    "model.save('model/cnn_model.h5')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9TeoTKuIXV0",
    "outputId": "9d605bfe-a3af-49dd-f542-cd1bb47da8e3"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ]
  }
 ]
}
